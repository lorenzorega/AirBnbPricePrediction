{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6291d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries and methods\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98c2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:9: DtypeWarning: Columns (43,87,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Splitting host verifications\n",
      "Cleaning the state\n",
      "Spliting amenities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n",
      "C:\\Users\\Lorenzo\\AppData\\Local\\Temp\\ipykernel_20168\\3053139432.py:220: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.insert(len(list(data)), amenity, 0)\n"
     ]
    }
   ],
   "source": [
    "''' Update notes by PRK Nov 10:\n",
    "        Taken out zipcode column entirely and added three more column removals (have commented in front)\n",
    "        Also commented out the print order'''\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "filename = '../Data/listings.csv'\n",
    "reviews_filename = '../Data/reviews_cleaned.csv'\n",
    "data = pd.read_csv(filename)\n",
    "reviews = pd.read_csv(reviews_filename, names = ['listing_id', 'comments'])\n",
    "# print(data.info)\n",
    "# print(list(data))\n",
    "# print(list(data)[43])\n",
    "# print(list(data)[87])\n",
    "# print(list(data)[88])\n",
    "\n",
    "# Taking out the unwanted columns\n",
    "print(len(data.columns))\n",
    "exit()\n",
    "data = pd.DataFrame.drop(data, columns=[\n",
    "    'host_name',\n",
    "    'notes', # Added PRK\n",
    "    'host_about', # Added PRK\n",
    "    'calendar_updated', # Added PRK\n",
    "    'host_acceptance_rate',\n",
    "    'description',\n",
    "    'thumbnail_url',\n",
    "    'experiences_offered',\n",
    "    'listing_url',\n",
    "    'name',\n",
    "    'summary',\n",
    "    'space',\n",
    "    'scrape_id',\n",
    "    'last_scraped',\n",
    "    'neighborhood_overview',\n",
    "    'transit',\n",
    "    'access',\n",
    "    'interaction',\n",
    "    'house_rules',\n",
    "    'medium_url',\n",
    "    'picture_url',\n",
    "    'xl_picture_url',\n",
    "    'host_url',\n",
    "    'host_thumbnail_url',\n",
    "    'host_picture_url',\n",
    "    'host_acceptance_rate',\n",
    "    'smart_location',\n",
    "    'license',\n",
    "    'jurisdiction_names',\n",
    "    'street',\n",
    "    'neighbourhood',\n",
    "    'country',\n",
    "    'country_code',\n",
    "    'host_location',\n",
    "    'host_neighbourhood',\n",
    "    'market',\n",
    "    'is_location_exact',\n",
    "    'square_feet',\n",
    "    'weekly_price',\n",
    "    'monthly_price',\n",
    "    'availability_30',\n",
    "    'availability_60',\n",
    "    'availability_90',\n",
    "    'availability_365',\n",
    "    'calendar_last_scraped',\n",
    "    'first_review',\n",
    "    'last_review',\n",
    "    'requires_license',\n",
    "    'calculated_host_listings_count',\n",
    "    'host_listings_count',\n",
    "\n",
    "     #discuss last two\n",
    "    'zipcode' # Added PRK\n",
    "\n",
    "])\n",
    "# print(list(data))\n",
    "\n",
    "\n",
    "print('Splitting host verifications')\n",
    "host_verification_set = set()\n",
    "\n",
    "def collect_host_verifications(entry):\n",
    "    entry_list = entry.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\" \", \"\").split(',')\n",
    "    for verification in entry_list:\n",
    "        if (verification != \"\" and verification != 'None'):\n",
    "            host_verification_set.add(verification +\"_verification\")\n",
    "\n",
    "data['host_verifications'].apply(collect_host_verifications)\n",
    "\n",
    "def generic_verification(entry, v):\n",
    "    entry_list = str(entry).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\" \", \"\").split(',')\n",
    "    for verification in entry_list:\n",
    "        if (verification + \"_verification\" == v):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "for v in host_verification_set:\n",
    "    data.insert(len(list(data)), v, 0)\n",
    "    data[v] = data['host_verifications'].apply(lambda x: generic_verification(x, v))\n",
    "\n",
    "data = pd.DataFrame.drop(data, columns=['host_verifications'])\n",
    "\n",
    "def clean_response_rate(entry):\n",
    "    if (type(entry) == str):\n",
    "        return entry.replace('%', '')\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "data['host_response_rate'] = data['host_response_rate'].apply(clean_response_rate)\n",
    "\n",
    "def clean_superhost(entry):\n",
    "    if (entry == 't'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['host_is_superhost'] = data['host_is_superhost'].apply(clean_superhost)\n",
    "data['host_has_profile_pic'] = data['host_has_profile_pic'].apply(clean_superhost)\n",
    "data['host_identity_verified'] = data['host_identity_verified'].apply(clean_superhost)\n",
    "data['has_availability'] = data['has_availability'].apply(clean_superhost)\n",
    "data['instant_bookable'] = data['instant_bookable'].apply(clean_superhost)\n",
    "data['is_business_travel_ready'] = data['is_business_travel_ready'].apply(clean_superhost)\n",
    "data['require_guest_profile_picture'] = data['require_guest_profile_picture'].apply(clean_superhost)\n",
    "data['require_guest_phone_verification'] = data['require_guest_phone_verification'].apply(clean_superhost)\n",
    "\n",
    "\"\"\"\n",
    "print(list(data))\n",
    "\n",
    "print(data['host_verifications'][0])\n",
    "for v in host_verification_set:\n",
    "    print(v, \" \", data[v][0])\n",
    "\"\"\"\n",
    "def clean_price(entry):\n",
    "    if (type(entry) != str and math.isnan(entry)):\n",
    "        return -55\n",
    "    entry1 = entry.replace('$', '').replace(',', '')\n",
    "    if (float(entry1) == 0):\n",
    "        return -55\n",
    "    return np.log(float(entry1))\n",
    "\n",
    "\n",
    "def clean_number(entry):\n",
    "    if (math.isnan(entry)):\n",
    "        return 0\n",
    "    else:\n",
    "        return entry\n",
    "def clean_number_removal(entry):\n",
    "    if (math.isnan(entry)):\n",
    "        return -55\n",
    "    else:\n",
    "        return entry\n",
    "data['bathrooms'] = data['bathrooms'].apply(clean_number_removal)\n",
    "data['bedrooms'] = data['bedrooms'].apply(clean_number_removal)\n",
    "data['beds'] = data['beds'].apply(clean_number_removal)\n",
    "data = data[data['bathrooms'] != -55]\n",
    "data = data[data['bedrooms'] != -55]\n",
    "data = data[data['beds'] != -55]\n",
    "\n",
    "def reviews_per_month_cleanup(entry):\n",
    "    if (math.isnan(entry)):\n",
    "        return 0\n",
    "    return entry\n",
    "\n",
    "data['reviews_per_month'] = data['reviews_per_month'].apply(reviews_per_month_cleanup)\n",
    "data['price'] = data['price'].apply(clean_price)\n",
    "data = data[data['price'] != -55]\n",
    "data['extra_people'] = data['extra_people'].apply(clean_price)\n",
    "data['security_deposit'] = data['security_deposit'].apply(clean_price)\n",
    "data['cleaning_fee'] = data['cleaning_fee'].apply(clean_price)\n",
    "def clean_listings_count(entry):\n",
    "    if (math.isnan(entry)):\n",
    "        return 1\n",
    "    return entry\n",
    "data['host_total_listings_count'] = data['host_total_listings_count'].apply(clean_listings_count)\n",
    "print(\"Cleaning the state\")\n",
    "def cleaned_state(entry):\n",
    "    if (isinstance(entry, str)):\n",
    "        if (entry.upper() == 'NY' or entry.upper == 'New York'):\n",
    "            return 'NY'\n",
    "        else:\n",
    "            return entry\n",
    "    elif math.isnan(entry):\n",
    "        return ''\n",
    "    else:\n",
    "        return entry\n",
    "data['state'] = data['state'].apply(cleaned_state)\n",
    "data = data[data['state'] == 'NY']\n",
    "state = {}\n",
    "def create_state_set(entry):\n",
    "    if (entry not in state):\n",
    "        state[entry] = 1\n",
    "    else:\n",
    "        state[entry] += 1\n",
    "\n",
    "data['state'].apply(create_state_set)\n",
    "# print(state)\n",
    "\n",
    "\n",
    "print('Spliting amenities')\n",
    "amenities_set = set()\n",
    "\n",
    "def collect_amenities(entry):\n",
    "    entry_list = entry.replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\" \", \"_\").split(',')\n",
    "    for am in entry_list:\n",
    "        if ('translation_missing' not in am and am != ''):\n",
    "            amenities_set.add(am)\n",
    "\n",
    "data['amenities'].apply(collect_amenities)\n",
    "#print(amenities_set)\n",
    "\n",
    "\n",
    "def generic_amenities(entry, amenity):\n",
    "    entry_list = entry.replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\" \", \"_\").split(',')\n",
    "    for am in entry_list:\n",
    "        if (am == amenity):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "for amenity in amenities_set:\n",
    "    data.insert(len(list(data)), amenity, 0)\n",
    "    data[amenity] = data['amenities'].apply(lambda x: generic_amenities(x, amenity))\n",
    "\n",
    "#print(data['amenities'][0])\n",
    "#for v in  amenities_set:\n",
    "#    print(v, \" \", data[v][0])\n",
    "\n",
    "\n",
    "#maybe drop the original column??\n",
    "data = pd.DataFrame.drop(data, columns=['amenities', 'state'])\n",
    "\n",
    "for col_name in ['property_type', 'bed_type',\n",
    "                 'room_type', 'neighbourhood_group_cleansed', 'city',\n",
    "                 'cancellation_policy', 'host_response_time', 'neighbourhood_cleansed']:\n",
    "    parsed_cols = pd.get_dummies(data[col_name])\n",
    "    data = data.drop(columns=[col_name])\n",
    "    data = pd.concat([data, parsed_cols], axis = 1)\n",
    "\n",
    "# Changing the host_since to number of days until 10 Nov 2018\n",
    "def clean_host_since(entry):\n",
    "    if (type(entry) != str and math.isnan(entry)):\n",
    "        return -55\n",
    "    return entry\n",
    "data['host_since'] = data['host_since'].apply(clean_host_since)\n",
    "data = data[data['host_since'] != -55]\n",
    "dummy_date = dt.datetime(2018,11,10)\n",
    "data.host_since = (dummy_date - pd.to_datetime(data.host_since))\n",
    "data.host_since = data.host_since.apply(lambda x: float(x.days))\n",
    "\n",
    "\n",
    "\n",
    "for col_name in ['review_scores_rating', 'review_scores_accuracy',\n",
    "                 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                 'review_scores_communication', 'review_scores_location',\n",
    "                 'review_scores_value']:\n",
    "    data[col_name] = data[col_name].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "data[col_name] = data[col_name].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "data = data.set_index('id').join(reviews.set_index('listing_id'))\n",
    "def clean_comments(entry):\n",
    "    if (type(entry) != str and math.isnan(entry)):\n",
    "        return 0\n",
    "    return entry\n",
    "data['comments'] = data['comments'].apply(clean_comments)\n",
    "data.to_csv('../Data/data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba7f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
